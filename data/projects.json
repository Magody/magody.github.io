[
  {
    "id": 98,
    "title": "MirAI: The Reflexive VTuber",
    "subtitle": "A fine-tuned base model LLM embedded into a real-time VTuber interface",
    "technologies": ["Python", "Unsloth", "LLaMA 3.2", "LoRA", "PyTorch", "OpenCV", "VTube Studio Integration"],
    "tags": ["Artificial Intelligence", "VTuber", "Language Models", "Personalized AI"],
    "image": "/images/projects/artificial_intelligence/assistants/MirAI/overview.jpg",
    "repo_link": "",
    "goal": "Create a reactive virtual personality capable of engaging in natural dialogue with users on Twitch or similar platforms using a base language model fine-tuned for personality, introspection, and memory alignment.",
    "interactive": false,
    "process_html": "<p>MirAI is an experimental AI-powered VTuber that blends LLM fine-tuning with real-time avatar interaction. Unlike traditional chatbots or instruction-tuned assistants, MirAI is powered by a base LLaMA 3.2 model fine-tuned using QLoRA via the Unsloth framework. The model is trained without pre-aligned conversational headers, enabling a freer and more stylized response generation.</p><h3>Key Features</h3><ul><li><strong>Custom Prompt Templates</strong>: Designed for base-style training, enabling creative and unpredictable responses.</li><li><strong>QLoRA Fine-Tuning</strong>: Lightweight adaptation using LoRA with Unsloth, optimized for systems with 12GB VRAM.</li><li><strong>Real-Time Inference</strong>: Uses <code>FastLanguageModel</code> with streaming generation to power live VTuber conversations.</li><li><strong>Fully Modular Architecture</strong>: Divided into config, model manager, and dataset transformer modules for flexibility and reuse.</li><li><strong>Base Model Behavioral Shaping</strong>: Carefully constructed dataset and prompt engineering to simulate memory, reflexivity, and improvisation.</li></ul><h3>Model Training Strategy</h3><p>MirAI is built on a <strong>base-style LLaMA 3.2 model</strong>, trained using SFT (Supervised Fine-Tuning) without headers like <code>&lt;|start_header_id|&gt;</code>. This allows more creative control and personalization but requires careful dataset formatting and iterative tuning to stabilize behavior.</p><ul><li><strong>Training Style:</strong> base</li><li><strong>LoRA Targets:</strong> q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj</li><li><strong>Precision:</strong> bfloat16 with quantization for 4-bit inference</li><li><strong>Headers:</strong> Custom prompt-based formatting (no instruction/response markup)</li></ul><h3>VTuber Integration</h3><p>MirAI uses a minimal desktop UI or OBS layer and syncs model output with an animated character avatar using <strong>VTube Studio</strong>. The system captures voice or text input, runs it through the model, and animates the avatarâ€™s expressions accordingly.</p><h3>Challenges & Resolutions</h3><ul><li><strong>Base Model Confusion:</strong> Initially struggled with maintaining consistent dialogue roles. Resolved with progressive training using masked templates.</li><li><strong>VRAM Limitations:</strong> Applied CPU offload and 4-bit quantization to support RTX 3060.</li><li><strong>Response Quality:</strong> Improved via prompt restructuring and behavioral refinement (e.g., sarcasm, identity).</li></ul><h3>Demo Video</h3><p>Watch MirAI come to life:</p><div style='padding:56.25% 0 0 0;position:relative;'><iframe src='https://player.vimeo.com/video/1068670869?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media' style='position:absolute;top:0;left:0;width:100%;height:100%;' title='Vtuber-Demo'></iframe></div><script src='https://player.vimeo.com/api/player.js'></script><h3>Future Plans</h3><ul><li>Integrate memory modules using a vector DB for long-term context retention.</li><li>Enable real-time voice recognition and speech synthesis (e.g., Whisper + ElevenLabs).</li><li>Refactor model with GRPO for alignment to emotional tone and stream interactivity.</li><li>Deploy on Twitch or YouTube Live with OBS overlays.</li></ul><h3>Takeaway</h3><p>MirAI is a step toward immersive, reflexive AI characters that blend language understanding with emotional nuance. It acts less like an assistant and more like a synthetic being with its own quirks, perfect for real-time entertainment and interaction.</p>",
    "featured": true,
    "path": ""
  },  
  {
    "id": 99,
    "title": "LLM J.A.R.V.I.S",
    "subtitle": "A n8n automation for a personalized AI assistant with a LLM",
    "technologies": ["Python", "n8n", "OpenAI", "Supabase", "ElevenLabs"],
    "tags": ["Artificial Intelligence", "Automation"],
    "image": "/images/projects/artificial_intelligence/assistants/LLM JARVIS/overview.png",
    "repo_link": "",
    "goal": "Develop an interactive virtual assistant with a user-friendly interface and robust backend integrations, enabling voice commands, multimedia processing, and automated responses.",
    "interactive": false,
    "process_html": "<p>The JARVIS Virtual Assistant combines a PyQt5 frontend and an n8n backend to provide a flexible and interactive user experience. The system processes text, audio, and images while leveraging OpenAI's language models and other tools for dynamic responses. Key features include:</p><ul><li>Real-time voice input and audio responses</li><li>Customizable user configurations</li><li>Support for Google Calendar and Gmail integrations</li><li>Text-to-speech via ElevenLabs</li><li>Context-aware interactions using Supabase for knowledge retrieval (RAG with vector database)</li></ul><h3>Frontend Features</h3><p>The PyQt5-based interface is designed for usability and aesthetic appeal:</p><ul><li>A circular waveform visualization for audio interactions</li><li>Customizable settings for user name and assistant mode</li><li>Text display with Markdown formatting</li><li>Intuitive buttons for toggling audio recording and settings</li></ul><img src='/images/projects/artificial_intelligence/assistants/LLM JARVIS/interface.png' alt='JARVIS Interface'><h3>Backend Architecture</h3><p>The backend is built using n8n for automation and integration:</p><ul><li>A webhook initiates the flow by processing multimedia and text inputs</li><li>Content routing based on input type (text, image, or audio)</li><li>AI-driven responses using OpenAI's language models</li><li>Multimedia transcription and analysis</li><li>Integration with Google Calendar, Gmail, and Supabase</li></ul><img src='/images/projects/artificial_intelligence/assistants/LLM JARVIS/architecture.png' alt='Backend Architecture'><h3>Demo Video</h3><p>Experience the JARVIS assistant in action:</p><iframe src='https://player.vimeo.com/video/1049889096?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 300px;'></iframe><h3>Key Objectives</h3><ul><li>Create a responsive and customizable assistant interface</li><li>Leverage AI to provide context-aware responses</li><li>Ensure seamless multimedia input handling</li><li>Automate routine tasks through integrations</li></ul><h3>Future Improvements</h3><p>Possible enhancements for the project include:</p><ul><li>Adding support for more languages</li><li>Improved NLP for better understanding of user intent</li><li>Integration with additional APIs for extended functionality</li></ul>",
    "featured": true,
    "path": ""
  },
  {
    "id": 100,
    "title": "Agent Learns to Survive",
    "subtitle": "Genetic Algorithms for Videogames",
    "technologies": ["Python", "NEAT", "Genetic Algorithms"],
    "tags": ["Deep Learning", "Genetic Algorithms", "Artificial Intelligence"],
    "image": "/images/projects/machine_learning/HumanLearnsToSurvive/1.png",
    "repo_link": "",
    "goal": "Simulate human survival in a videogame using genetic algorithms and neural networks.",
    "interactive": false,
    "process_html": "<p>Humans adapt and, in certain cases, evolve. It is fascinating to replicate this process. In this project, 50 humans are set free in an unknown environment. At the beginning, they do not know what to do. When these humans spend too much energy or touch a monster several times, they die. Their goal is to survive as long as possible and collect as much green energy as possible.</p><iframe src='https://player.vimeo.com/video/574751509?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 300px;'></iframe><p>In this project, I used NEAT, which combines neural networks and genetic algorithms. This project is inspired by 'AI learns to play Flappy Bird.'</p><img src='/images/projects/machine_learning/HumanLearnsToSurvive/0.jpg' alt='Genetic Algorithms'><p>Of course, I also implemented 'Flappy Bird learns to play videogames.' Just search in my portfolio.</p>",
    "featured": true,
    "path": ""
  },
  {
    "id": 101,
    "title": "Digit Identifier",
    "subtitle": "Handwritten Digit Recognition",
    "technologies": ["JavaScript", "TensorFlow.js", "HTML Canvas"],
    "tags": ["Interactive", "Supervised Learning", "Artificial Intelligence"],
    "image": "/images/projects/machine_learning/DigitsRecognition/0.png",
    "repo_link": "",
    "goal": "Build a handwritten digit recognition tool using TensorFlow.js and HTML Canvas.",
    "interactive": true,
    "process_html": "<p>Users draw a digit on the canvas, which is resized and processed by a TensorFlow.js model trained on the MNIST dataset to predict the digit with high accuracy.</p>",
    "featured": true,
    "path": "/projects/interactive/digit-identifier"
  },
  {
    "id": 102,
    "title": "Recommendation System with Collaborative Filtering",
    "subtitle": "Cost-effective recommendation system for SMEs",
    "technologies": ["Python", "Flask", "Matrix Factorization"],
    "tags": ["Recommendation Systems", "Supervised Learning", "Artificial Intelligence"],
    "image": "/images/projects/machine_learning/RecommendationSystemMatrix/0.png",
    "repo_link": "",
    "goal": "Develop a cost-effective and reusable recommendation system for small and medium-sized companies using collaborative filtering and matrix factorization.",
    "interactive": false,
    "process_html": "<p>Many companies lack recommendation systems due to limited knowledge or budget constraints. However, between 40% and 60% of content consumption for large companies comes from recommendations (according to Google). This project addresses this gap by creating a cost-effective and reusable recommendation system to help companies increase profits by identifying similarities in customers' tastes collaboratively.</p><div><img src='/images/projects/machine_learning/RecommendationSystemMatrix/0.png' alt='Recommendation System Diagram'></div><p>A diagram was designed to outline the recommendation process: starting with a large number of products, possible candidates are generated with matrix factorization, similarities between products are calculated, and the top 10 products with the best scores are recommended.</p><div><img src='/images/projects/machine_learning/RecommendationSystemMatrix/1.png' alt='Matrix Factorization Diagram'></div><p>The essence of matrix factorization is predicting the entire score table of users, including unqualified values. This is achieved by multiplying a matrix A by a matrix B and optimizing parameters until the prediction error is very low, allowing accurate prediction of unknown values.</p><div><img src='/images/projects/machine_learning/RecommendationSystemMatrix/2.png' alt='Matrix Optimization'></div><p>Using Python and Flask, a small product store was designed, where users can rate products on a scale from 1 to 5.</p><div><img src='/images/projects/machine_learning/RecommendationSystemMatrix/3.png' alt='Product Store'><img src='/images/projects/machine_learning/RecommendationSystemMatrix/4.png' alt='Product Ratings'></div><p>If Person A and Person B share similar tastes, collaborative filtering predicts that if B likes a new product, A might also like it. Matrix factorization generates candidates and uses context and search history to refine recommendations. Known products are discarded to ensure fresh recommendations.</p><div><img src='/images/projects/machine_learning/RecommendationSystemMatrix/5.png' alt='Collaborative Filtering Process'><p>Note: An administration panel was also developed for this project.</p><img src='/images/projects/machine_learning/RecommendationSystemMatrix/6.png' alt='Admin Panel'></div>",
    "featured": true,
    "path": ""
  },  
  {
    "id": 103,
    "title": "A.I. Solve a Random Labyrinth",
    "subtitle": "Artificial Intelligence Finds Paths in Labyrinths",
    "technologies": ["Java"],
    "tags": ["Artificial Intelligence", "Algorithmic"],
    "image": "/images/projects/artificial_intelligence/SolveLabyrinth/0.png",
    "repo_link": "",
    "goal": "Showcase how artificial intelligence solves labyrinths using recursive algorithms.",
    "interactive": false,
    "process_html": "<h2>A.I. Solve a Random Labyrinth</h2><p>By means of recursion, paths are generated in all directions as long as there is no wall, until the 'yellow ball' is reached. This is one of a bunch of pathfinding algorithms!</p><h3>Demonstration Video</h3><p>Watch the A.I. solve a labyrinth in the following video:</p><iframe src='https://player.vimeo.com/video/576411097?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 100%;'></iframe><script src='https://player.vimeo.com/api/player.js'></script><h3>Key Features</h3><p>Using a matrix, we can change the objective point, and the A.I. will find the correct path. If the point is unreachable, then after a short loop, the A.I. decides it is impossible to find a solution.</p><h3>Visual Examples</h3><div id='image_container'><img src='/images/projects/artificial_intelligence/SolveLabyrinth/0.png' alt='Labyrinth example 1' style='max-width: 100%;'><img src='/images/projects/artificial_intelligence/SolveLabyrinth/1.png' alt='Labyrinth example 2' style='max-width: 100%;'></div>",
    "featured": false,
    "path": ""
  },
  {
    "id": 104,
    "title": "Game of Life",
    "subtitle": "Conway's Game of Life",
    "technologies": ["JavaScript", "HTML Canvas"],
    "tags": ["Interactive", "Game"],
    "image": "/images/projects/applications/GameOfLife/0.png",
    "repo_link": "",
    "goal": "Implement Conway's Game of Life using HTML Canvas.",
    "interactive": true,
    "process_html": "",
    "featured": false,
    "path": "/projects/interactive/game-of-life"
  },
  {
    "id": 105,
    "title": "A.I. Solve the 8-Puzzle",
    "subtitle": "Artificial Intelligence Solves a Classic Puzzle",
    "technologies": ["Java"],
    "tags": ["Artificial Intelligence", "Algorithmic"],
    "image": "/images/projects/artificial_intelligence/Puzzle8/0.png",
    "repo_link": "",
    "goal": "Document how artificial intelligence solves the classic 8-Puzzle problem using backtracking.",
    "interactive": false,
    "process_html": "<h2>A.I. Solve the 8-Puzzle</h2><p>Is beautiful to see clasic algorithms solving complex problems in a deterministic way.</p><h3>Backtracking Algorithm</h3><p>Backtracking is an optimized brute force technique. To solve this puzzle, we always find a first solution very quickly, but we look for the best one. Gradually, and by means of quotas, we optimize the possibilities.</p><h3>Demonstration Video</h3><p>In the following video, the A.I. creates a solution for the puzzle and shows us the solution with 'arrows.' With that help, the human can complete the puzzle correctly.</p><iframe src='https://player.vimeo.com/video/578221631?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 100%;'></iframe><script src='https://player.vimeo.com/api/player.js'></script><h3>Key Insights</h3><ul><li>Recursion can generate paths that have already been explored, thus creating a loop.</li><li>The complexity of the program increases significantly when dealing with a 4x4 matrix.</li></ul>",
    "featured": false,
    "path": ""
  },
  {
    "id": 106,
    "title": "A.I. Play TicTacToe",
    "subtitle": "Artificial Intelligence Playing TicTacToe Using Tree Structures",
    "technologies": ["MATLAB"],
    "tags": ["Artificial Intelligence", "Algorithmic"],
    "image": "/images/projects/artificial_intelligence/TicTacToe/0.png",
    "repo_link": "",
    "goal": "Demonstrate how artificial intelligence can play TicTacToe using tree-based algorithms and strategies.",
    "interactive": false,
    "process_html": "<h2>A.I. Play TicTacToe</h2><p>By means of data structures, a tree is generated with all possible moves and, according to a score, the move with the highest score is chosen. Each loss in the tree is a negative value, and each draw/victory is a positive value.</p><h3>Player vs A.I.</h3><iframe src='https://player.vimeo.com/video/576932532?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 100%;'></iframe><h3>A.I. vs A.I.</h3><iframe src='https://player.vimeo.com/video/576932510?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 100%;'></iframe><h3>Tree Pruning</h3><p>The program receives the state of the board and depending on it will generate all possible paths but pruning unviable branches (branches with a cost less than a 'minimum cost').</p><img src='/images/projects/artificial_intelligence/TicTacToe/1.png' alt='Tree pruning example' style='max-width: 100%;'><h3>Strategic Moves</h3><p>The most experienced players place the first move on a corner every time they start first. This gives the opponent more opportunity to make a mistake. If the opponent responds by placing anywhere but in the center, the chances of victory increase, so the algorithm chooses one of the 4 corners as the first move.</p><img src='/images/projects/artificial_intelligence/TicTacToe/2.png' alt='First move strategy' style='max-width: 100%;'><p>If the opponent plays first and starts in one corner, he always places the second move in the center. The second move should always be placed in the opposite corner, because we would automatically lose, without turning back. With this strategy, it is estimated that the game will probably end in a draw. In theory, you can win from this position, but the opponent would have to make a big mistake.</p><img src='/images/projects/artificial_intelligence/TicTacToe/3.png' alt='Second move strategy for corners' style='max-width: 100%;'><p>When the opponent starts by placing in the center, the second move is placed in a corner. Basically, there is no way to win, only to draw, from this position; unless the opponent makes a mistake.</p><img src='/images/projects/artificial_intelligence/TicTacToe/4.png' alt='Second move strategy for center' style='max-width: 100%;'><p>If the component places the first leg on an edge (side) instead of on a corner or in the center, there is a chance of a hit.</p><img src='/images/projects/artificial_intelligence/TicTacToe/5.png' alt='Edge placement strategy' style='max-width: 100%;'><p>Using the first move and second move strategies, the computer will never compute the tree for a board with 9 or 8 empty spaces. This is a good improvement.</p><h3>Counter Plays</h3><p>The 'counterplay' function is used to fill in some of the weaknesses that the algorithm may have and also to feed it with 'good plays', i.e., if we find a 'good play' where the victory is clear, we apply this counterplay to pay off.</p><img src='/images/projects/artificial_intelligence/TicTacToe/6.png' alt='Counterplay example' style='max-width: 100%;'><h3>Additional Resources</h3><ul><li><a href='/images/projects/artificial_intelligence/TicTacToe/report.pdf' target='_blank'>See the report</a></li><li><a href='/images/projects/artificial_intelligence/TicTacToe/strategies.pdf' target='_blank'>Learn about the strategies</a></li><li><a href='/images/projects/artificial_intelligence/TicTacToe/presentation.pdf' target='_blank'>See the class presentation</a></li></ul>",
    "featured": false,
    "path": ""
  },
  {
    "id": 107,
    "title": "Creating Association Rules for a Shopping Cart",
    "subtitle": "Using the Apriori Algorithm to Discover Patterns in Restaurant Transactions",
    "technologies": ["Python"],
    "tags": ["Data Science"],
    "image": "/images/projects/data_science/AssociationRulesRestaurant/0.png",
    "repo_link": "",
    "path": "",
    "goal": "Demonstrate the use of the Apriori algorithm to generate association rules for restaurant transactions.",
    "interactive": false,
    "featured": false,
    "process_html": "<h2>Creating Association Rules for a Shopping Cart</h2><p>I use the Apriori algorithm to perform Data Mining over a dataset of 194k transactions in a restaurant. The objective is to create a rule like 'If a person buys {A}, then there exists a high probability that they will buy {B}.'</p><p>This way, we can make recommendations, discounts, and other marketing strategies with items that we know are often bought together.</p><img src='/images/projects/data_science/AssociationRulesRestaurant/10.png' alt='Apriori example' style='max-width: 100%;'><h3>The Dataset</h3><p>The dataset looks like this:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/1.png' alt='Dataset structure' style='max-width: 100%;'><p>These are the columns and types:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/2.png' alt='Column types' style='max-width: 100%;'><h3>Feature Engineering</h3><p>To get better results, I simplified the Item Name feature. For example, every food that begins with 'Chicken' is categorized under the same category. Then, we could apply other recommendation techniques to create a pipeline of two ML algorithms for better recommendations.</p><img src='/images/projects/data_science/AssociationRulesRestaurant/3.png' alt='Feature engineering example' style='max-width: 100%;'><p>The feature engineering reduced the amount of items from 381 to 87, resulting in cleaner association rules.</p><img src='/images/projects/data_science/AssociationRulesRestaurant/4.png' alt='Reduced items' style='max-width: 100%;'><h3>Sparse Matrix Transformation</h3><p>I transformed the transactions into a sparse matrix with ones in the position of the food ordered for that transaction:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/5.png' alt='Sparse matrix transformation' style='max-width: 100%;'><h3>Frequent Itemsets</h3><p>The most frequently ordered food with at least 10% support across all transactions is identified:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/6.png' alt='Frequent itemsets' style='max-width: 100%;'><h3>Association Rules</h3><p>It's time to apply Apriori. The first five association rules are:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/7.png' alt='First five rules' style='max-width: 100%;'><p>The top five association rules with the highest LIFT are:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/8.png' alt='Top five rules by LIFT' style='max-width: 100%;'><p>Comparing these rules, we get the following insights:</p><img src='/images/projects/data_science/AssociationRulesRestaurant/9.png' alt='Rules comparison' style='max-width: 100%;'><h3>Conclusions</h3><ul><li>If we sort the association rules by confidence, there are items with more than 95% confidence. Lift is a very good metric, but in production, we should test the best association rules based on both LIFT and confidence and keep the rules with the best results.</li><li>If a person buys {mango}, that person probably will want {plain, onion}, and vice versa.</li><li>If a person buys {plain, pilau}, that person probably will want {mango}, and vice versa.</li><li>If a person buys {mint}, that person probably will want {chicken, plain}.</li><li>Now we have to validate the rules. For example, if people who ask for {plain, pilau} are recommended {mango}, there is a high chance they will buy mango, even if they did not think about it.</li><li>It is important to note that {A}=>{B} is not always the same as {B}=>{A}. In this restaurant study case, the rules can be inverted for some items.</li></ul>"
  },
  {
    "id": 108,
    "title": "Clustering and Sentimental Analysis",
    "subtitle": "Improving YouTube Performance for Ken Jee Using Data Analysis",
    "technologies": ["Python", "EDA", "Clustering", "Sentiment Analysis"],
    "tags": ["Data Science", "Unsupervised Learning", "Artificial Intelligence"],
    "image": "/images/projects/data_science/EDA_KenJee/3.png",
    "repo_link": "https://www.kaggle.com/magody/eda-clustering-and-sentimental-analysis",
    "path": "",
    "goal": "Perform an exploratory data analysis, clustering, and sentiment analysis to improve Ken Jee's YouTube performance.",
    "interactive": false,
    "featured": true,
    "process_html": "<h2>EDA, Clustering and Sentimental Analysis</h2><p>Exploratory Data Analysis and Machine Learning to help YouTuber Ken Jee improve performance. The full analysis is on Kaggle: <a href='https://www.kaggle.com/magody/eda-clustering-and-sentimental-analysis'>Kaggle Project</a>.</p><img src='/images/projects/data_science/EDA_KenJee/0.png' alt='EDA Overview' style='max-width: 100%;'><p>I made 12+ important questions to improve CTR, subscription ratio, and more. In this analysis, I've performed EDA over Ken Jee's dataset. I've modeled clustering with TF-IDF for title topics (Question 4) and for user comments (Question 13) and included some sentiment analysis. The rest involves simple analysis.</p><img src='/images/projects/data_science/EDA_KenJee/1.png' alt='CTR analysis' style='max-width: 100%;'><h3>Key Insights</h3><p>Insights about the best thumbnail-title combinations:</p><img src='/images/projects/data_science/EDA_KenJee/2.png' alt='Thumbnail-title insights' style='max-width: 100%;'><p>A deep CTR analysis with correlations:</p><img src='/images/projects/data_science/EDA_KenJee/3.png' alt='CTR correlations' style='max-width: 100%;'><p>Using NLP, I've clustered the most important topics to repeat them in future content:</p><img src='/images/projects/data_science/EDA_KenJee/4.png' alt='Topic clustering' style='max-width: 100%;'><p>Sentiment analysis revealed interesting recommendations from negative comments:</p><img src='/images/projects/data_science/EDA_KenJee/5.png' alt='Sentiment analysis' style='max-width: 100%;'><h3>Conclusions and Recommendations</h3><h4>From Sentiment Analysis Comments:</h4><ul><li>People dislike clickbait titles and 'awkward' faces in thumbnails. Since showing a face in thumbnails is an SEO-proven strategy, you may want to ignore this or adjust the photo strategy.</li><li>Improve audio/mic quality.</li><li>Provide new information instead of 'boring' or repetitive topics.</li><li>Speak with a more natural and faster rhythm.</li></ul><h4>To Increase CTR:</h4><ul><li>Include psychological triggers in videos, as most don't have them.</li><li>Use odd numbers (3, 5, 7, 10) in titles. Avoid even numbers as they may feel 'incomplete.'</li><li>The best CTR titles in the channel are 'Should you,' 'you,' beginner/started guides, or specific projects. Redirect viewers to high-subscription-rate videos when a project ends.</li><li>Avoid cluttering thumbnails with multiple objects.</li><li>Best video clusters for high CTR: tutorials, data science life (portfolio, daily, learning, etc.), and job-related topics.</li><li>Expand topics by linking them to mainstream subjects (e.g., Crypto) while clearly indicating a data science angle in the thumbnail.</li></ul><h4>To Increase Subscription Rate:</h4><ul><li>Link videos with high CTR and average watch time to those with high subscription rates using cards, pinned comments, and descriptions.</li><li>Topics that attract more subscribers: beginner data science introductions, experiences ('If I had to start again...'), and recommendation videos ('3 Reasons You Should NOT...').</li><li>Topics that lead to unsubscribes: Q&A and channel announcements.</li></ul><h4>To Increase Average Watch Time:</h4><ul><li>Use curiosity triggers like 'The Secret...' and talk about unique topics.</li><li>Include urgency triggers like 'Why Right NOW is a Great Time...'</li><li>Focus on topics like 'What You Need to Know...' but avoid repetitive clickbait. Hide clickbait strategies subtly.</li><li>Use phrases like 'You need to start...' sparingly to avoid redundancy.</li></ul>"
  },
  {
    "id": 109,
    "title": "Gesture Recognition Using Android",
    "subtitle": "Using Gyroscope and Accelerometer Data to Recognize Gestures",
    "technologies": ["Python", "AndroidStudio", "Angular"],
    "tags": ["Deep Learning", "Supervised Learning", "Artificial Intelligence"],
    "image": "/images/projects/machine_learning/AndroidGestureRecognition/2.png",
    "repo_link": "",
    "path": "",
    "goal": "Develop a gesture recognition system using gyroscope and accelerometer data from Android devices.",
    "interactive": false,
    "featured": true,
    "process_html": "<h2>Gesture Recognition Using Android</h2><p>The project consists of recognizing gestures made with the cell phone, using the phone's accelerometer and gyroscope to predict a custom type of movement that was previously trained and send that prediction to a server. The server then draws symbols on the screen according to the gesture predicted by the network. This is a small step toward saving any type of gesture in the future and using the cell phone as an augmented reality controller in applications or video games on the web.</p><div><img src='/images/projects/machine_learning/AndroidGestureRecognition/0.png' alt='Overview of gesture recognition' style='max-width: 100%;'></div><p>Through the movement of the hand with the cell phone, the sensors collect data, and this data is used to train a feedforward neural network.</p><div><img src='/images/projects/machine_learning/AndroidGestureRecognition/1.png' alt='Training process overview' style='max-width: 100%;'></div><p>The system has a CRUD of operations for managing gestures and other user information. For training, at least 10 repetitions must be stored for each gesture. From these examples, another 200 are generated using data augmentation. Several mathematical operations are applied to the data to generate new data while preserving the main essence of the gestures.</p><div><img src='/images/projects/machine_learning/AndroidGestureRecognition/2.png' alt='Data augmentation' style='max-width: 100%;'></div><p>The system also has a data management panel created using Angular.</p><div><img src='/images/projects/machine_learning/AndroidGestureRecognition/3.png' alt='Angular management panel' style='max-width: 100%;'></div><p>The neural network receives an input of 600 variables: 100 data points for each axis and for each type of sensor (Gyroscope and Accelerometer). Based on this input, it predicts the type of gesture. The application connects to a server to communicate its prediction, which then draws an arrow on the screen for a lateral movement or a cross for a shooting movement. These were the two main types of gestures the network was trained with.</p><div><img src='/images/projects/machine_learning/AndroidGestureRecognition/4.png' alt='Server-based gesture predictions' style='max-width: 100%;'><img src='/images/projects/machine_learning/AndroidGestureRecognition/5.png' alt='Gesture recognition example' style='max-width: 100%;'></div><p>Few epochs and a learning rate of 0.01 were used for training, with 600 input neurons, 35 neurons in the first hidden layer, 18 neurons in the second hidden layer, and N neurons in the output layer (N depends on the number of gestures saved by the user). As a conclusion, a hit rate of 80% was obtained. The neural network struggled to recognize gesture types when the device was used in streaming mode (live), but in static predictions, where gestures were saved and then sent for prediction, the network performed correctly. For better signal handling, it is recommended to use convolutional or recurrent neural networks to achieve higher accuracy scores.</p>"
  },
  {
    "id": 110,
    "title": "Adodot",
    "subtitle": "Simple RPG game with a lot of mini mechanics",
    "technologies": ["C#", "Unity"],
    "tags": ["Game"],
    "image": "/images/projects/videogames/Adodot/0.png",
    "repo_link": "",
    "goal": "Develop a simple RPG game featuring various mechanics like magic reflection, barriers, flying, teleportation, and more.",
    "interactive": false,
    "process_html": "<p>This is a simple game with a main character with these skills: reflect magic, make a barrier, fly, teleport, stop time, go back in time, invoke a fireball, and transform into a super saiyan.</p><iframe src='https://player.vimeo.com/video/574746497?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 300px;'></iframe><p>If you want to see more technical details, please consider visiting: <a href='https://magody.github.io/OldPortfolio/Lenguajes/CSharp/Adodot/adodotValley.pdf' target='_blank'>Adodot Valley Technical Details</a>.</p><h3>History</h3><p>Hyul is the main character, who wakes up in the middle of a village without most of his memories of his past. He remembers many of the customs of a planet called Earth and that he comes from there. He learned to communicate with the villagers and they welcomed him as one of their own. As he conversed more fluently with the leaders, he learned that the planet is going through a crisis in which many plagues of monsters fall from meteorites and torment the people. Gradually, they were cornered in \"protected\" sectors like the valley where he woke up.</p><p>The richest people enjoy abundant magical power that allows them to establish barriers in their cities to protect themselves from the monsters. However, Adodot Valley has only poor people who try not to get involved in the war. Hyul helped where he could in exchange for food and other necessities. The town was surrounded by huge mountains and the only exits contained hundreds of monsters. Many village heroes tried to break through but failed.</p><p>As people moved from place to place, they took common goods, ornaments, and pets but left behind books of knowledge. The passing of decades caused humanity on that planet to forget their history, being governed only by what the king of the day said through well-trained magician messengers who appeared not to protect but to collect resources. Currently, there are only five old sages with the knowledge to heal, destroy, and create scattered around the world.</p><p>Hyul will seek every way to help Adodot Valley, gathering as much knowledge as possible to face first the monsters, then the noble classes while seeking the reason for his appearance on that planet and the origin of the monster meteorites.</p>",
    "featured": false,
    "path": ""
  },
  {
    "id": 111,
    "title": "Ethical Owl",
    "subtitle": "OS and Hacking Simulation",
    "technologies": ["C", "Allegro Library"],
    "tags": ["Game"],
    "image": "/images/projects/videogames/EthicalOwl/mr robot.jpg",
    "repo_link": "",
    "goal": "Simulate ethical hacking and OS functionality in an educational and interactive way.",
    "interactive": false,
    "process_html": "<p>ETHICAL OWL is a game inspired by the famous <i>Mr. Robot</i> series, featuring a young computer security engineer who uses his skills to protect the people he cares about. The game introduces players to ethical hacking concepts and file management in a didactic way.</p><iframe src='https://player.vimeo.com/video/574746935?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 300px;'></iframe><h3>Sprites</h3><p>Many resources were taken from other video games for non-commercial purposes, such as Stardew Valley, Final Fantasy V, and PokÃ©mon.</p><img src='/images/projects/videogames/EthicalOwl/plantilla.jpg' alt='Sprite Resources'><img src='/images/projects/videogames/EthicalOwl/fondoCuarto.png' alt='Room Background'><h3>Piano</h3><p>Approach the brown piano bench and press the keys (<i>j, i, l, k</i>). Press <i>a</i> to open a black window and input a song title like <i>symphony</i>. A .txt file will be created, and you can compose music using on-screen key indicators. To exit, press ENTER.</p><img src='/images/projects/videogames/EthicalOwl/notas.jpg' alt='Piano Notes'><h3>The Operative System</h3><p>Approach the blue bench and press <i>a</i> to open a small Windows simulator. Click the bottom left circle with the Windows logo to access the shutdown option or close the menu by clicking the circle again.</p><img src='/images/projects/videogames/EthicalOwl/pc.jpg' alt='OS Simulator'><p>Four functional programs are available:</p><h3>Notepad</h3><p>This program allows quick information storage. Enter a title and press ENTER to create a .txt file. All written content will be documented in the file. Exit by pressing ESC.</p><h3>Poli Play Piano Program</h3><p>This program reads text files and converts letters to sounds. Input the file name (e.g., <i>test</i>) to play its contents.</p><img src='/images/projects/videogames/EthicalOwl/piano.png' alt='Poli Play Piano'><h3>SQL++</h3><p>A database is a collection of organized information accessible to computer programs. This feature demonstrates database functionalities.</p><img src='/images/projects/videogames/EthicalOwl/sqlmas.bmp' alt='SQL++'><h3>Fsociety</h3><p>This program allows the creation of scripts via simple commands. For example, the command <i>/permute [word]</i> generates permutations of the word. Additional CMD interactions include:</p><ul><li><i>/system mode 200</i>: Enlarges the CMD.</li><li><i>/system color 0a</i>: Changes CMD text color.</li><li><i>/system start [file]</i>: Executes files or opens web pages.</li><li><i>/system ping [website]</i>: Sends service requests, simulating DDoS attacks.</li><li><i>/system copy /b 1.jpg+2.rar 3.jpg</i>: Merges files into an image.</li><li><i>/system fc /b 1.txt 3.txt</i>: Compares files in binary mode.</li></ul><img src='/images/projects/videogames/EthicalOwl/permutar.jpg' alt='Script Example'><img src='/images/projects/videogames/EthicalOwl/mr robot.jpg' alt='Mr. Robot'><img src='/images/projects/videogames/EthicalOwl/cmd.jpg' alt='CMD Interface'><h3>Allegro Library</h3><p>The Allegro library was used for game development. Allegro is a free and open-source library for C language-based game programming. It provides functions for graphics, sound, input devices, and more.</p>",
    "featured": false,
    "path": ""
  },
  {
    "id": 112,
    "title": "Poli Is Strange",
    "subtitle": "Mini RPG made in Java only",
    "technologies": ["Java"],
    "tags": ["Game"],
    "image": "/images/projects/videogames/PoliIsStrange/8.png",
    "repo_link": "",
    "goal": "Develop a mini-RPG game using Java to learn the basics of 2D game development, including mechanics like collisions, AI, and decision-making.",
    "interactive": false,
    "process_html": "<p>I developed a small mini-game using only Java to understand the basics of 2D games. Players can destroy enemies, collect money for investments or the store, and use magic. Controls:</p><ul><li>Up = W</li><li>Down = S</li><li>Left = A</li><li>Right = D</li><li>Exit = ESCAPE</li><li>Run = SHIFT</li><li>Power Fireball = 1</li><li>Time Power = T</li><li>Fire Gun = E</li><li>Reload Gun = R</li><li>Sword Attack = 2</li></ul><iframe src='https://player.vimeo.com/video/578858878?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen style='width: 100%; height: 300px;'></iframe><h3>Important Objectives of the Project</h3><ul><li>Design of a video game in general</li><li>AI capable of playing Tic-tac-toe</li><li>Data protection (Security)</li><li>Backtracking actions by x time</li><li>Decision making in games</li></ul><h3>Design Diary</h3><p>Some art was designed manually:</p><img src='/images/projects/videogames/PoliIsStrange/1.png' alt='Game Art'><p>We implemented a Tycoon feature where the player can invest and generate extra percentages over time:</p><img src='/images/projects/videogames/PoliIsStrange/2.png' alt='Tycoon Feature'><h3>Bullet</h3><p>A pistol allows the player to shoot bullets at enemies:</p><img src='/images/projects/videogames/PoliIsStrange/3.png' alt='Bullet Implementation'><h3>Store</h3><p>Players can purchase items for their adventure:</p><img src='/images/projects/videogames/PoliIsStrange/4.png' alt='Game Store'><h3>Final Boss</h3><p>A powerful final boss appears after defeating a certain number of enemies:</p><img src='/images/projects/videogames/PoliIsStrange/5.png' alt='Final Boss'><h3>Collisions</h3><p>Collisions were implemented using hitboxes with the Java Rectangle class:</p><img src='/images/projects/videogames/PoliIsStrange/6.png' alt='Collisions'><h3>HUD</h3><p>The HUD was implemented using background images and Java's Graphics class for drawing the interface:</p><img src='/images/projects/videogames/PoliIsStrange/7.png' alt='HUD'><h3>Fireball</h3><p>A fireball mechanic similar to bullets but dependent on the player's mana:</p><img src='/images/projects/videogames/PoliIsStrange/8.png' alt='Fireball'><h3>TicTacToe</h3><p>The game includes a mini TicTacToe feature inspired by a previous Matlab project:</p><img src='/images/projects/videogames/PoliIsStrange/9.png' alt='TicTacToe'><h3>Cheats</h3><p>GTA San Andreas-style cheats were implemented using data structures:</p><img src='/images/projects/videogames/PoliIsStrange/10.png' alt='Cheats'><h3>Back in Time</h3><p>The player can revert to previous states using saved snapshots. This mechanic is inspired by <i>Life is Strange</i> and <i>League of Legends</i>:</p><img src='/images/projects/videogames/PoliIsStrange/11.png' alt='Back in Time'><h3>Decisions That Modify the Environment</h3><p>Players can save or abandon NPCs, impacting the environment and story:</p><img src='/images/projects/videogames/PoliIsStrange/12.png' alt='Decisions'><h3>Finite-State Machine</h3><p>NPCs are represented as finite-state machines:</p><img src='/images/projects/videogames/PoliIsStrange/13.png' alt='Finite-State Machine'><h3>Presentation</h3><p>See the presentation made in class <a href='/images/projects/videogames/PoliIsStrange/presentationPoliIsStrange.pdf' target='_blank'>here</a>.</p>",
    "featured": false,
    "path": ""
  },
  {
    "id": 113,
    "title": "Undetectable Web Scrapper",
    "subtitle": "Web Scrapping with Selenium (Bot Undetectable)",
    "technologies": ["Python", "Selenium"],
    "tags": ["Web Scraping", "Data Analysis"],
    "image": "/images/projects/web_scrapping/anime_flv_scrapper/0.png",
    "repo_link": "",
    "goal": "Develop a web scraper for AnimeFLV using Selenium to collect data for sentiment analysis and other insights.",
    "interactive": false,
    "process_html": "<p>This project focuses on web scraping AnimeFLV for collecting and analyzing anime data, including sentiment analysis based on user reactions.</p><p>The scraping process utilizes Selenium to navigate through pages and perform logins due to the siteâ€™s restrictions and popups.</p><h3>Steps and Features</h3><ul><li>Login simulation with Selenium.</li><li>Job system for handling scraping tasks in batches.</li><li>ETL process for merging, cleaning, and analyzing data.</li><li>Sentiment analysis based on DisQus reactions embedded in iframes.</li></ul><h3>Collected Data</h3><ul><li>Anime titles, descriptions, tags (for NLP processing).</li><li>Scoring, votes, number of episodes, follower counts.</li><li>User reactions (e.g., funny, loved, sad, surprising).</li></ul><h3>Results and Analysis</h3><p>After collecting data, various analyses were performed:</p><ul><li>Most liked animes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/liked(relative).png' alt='Most Liked Animes'><ul><li>Funniest animes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/funny(relative).png' alt='Funniest Animes'><ul><li>Most loved animes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/loved(relative).png' alt='Most Loved Animes'><ul><li>Saddest animes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/sad(relative).png' alt='Saddest Animes'><ul><li>Most surprising animes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/surprise(relative).png' alt='Most Surprising Animes'><ul><li>Animes causing anger:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/angry(relative).png' alt='Animes Causing Anger'><h3>Popular Animes</h3><p>Analysis by different metrics:</p><ul><li>By followers:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/df_popular_followers(relative).png' alt='Popular by Followers'><ul><li>By reactions count:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/df_popular_reactions(relative).png' alt='Popular by Reactions'><ul><li>By votes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/df_popular_votes(relative).png' alt='Popular by Votes'><ul><li>Best rated animes:</li></ul><img src='/images/projects/web_scrapping/anime_flv_scrapper/df_best_rated(relative).png' alt='Best Rated Animes'><h3>Technical Details</h3><ul><li>Login requires an account to access reactions.</li><li>Selenium handles form filling, popup ads, and login challenges.</li><li>Job system splits scraping tasks into manageable parts, saved as CSV files.</li><li>ETL process merges and cleans data for feature engineering and sentiment analysis.</li></ul>",
    "featured": false,
    "path": ""
  }
  
  
  
  
  
  
]